import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix, roc_auc_score
)

st.set_page_config(page_title="Churn Prediction App", page_icon="üìä")

st.title("üìâ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (Churn)")

# --- File upload ---
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª")
uploaded = st.file_uploader("CSV-—Ñ–∞–π–ª", type="csv")

if uploaded is None:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª")
    st.stop()

# --- Load data ---
df = pd.read_csv(uploaded)
st.header("üîé –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
st.write(df.head())

# --- Basic info ---
st.header("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
st.subheader("–ü—Ä–æ–ø—É—Å–∫–∏")
st.write(df.isna().sum())

# --- Graph #1: Target distribution ---
if "churn" in df.columns:
    st.subheader("üìå –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ‚Äî churn")

    fig, ax = plt.subplots()
    sns.countplot(x=df["churn"], ax=ax)
    ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ churn")
    st.pyplot(fig)

# --- Preprocessing ---
if "customerid" in df.columns:
    df.drop("customerid", axis=1, inplace=True)

for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = LabelEncoder().fit_transform(df[col])

# --- Graph #2: Correlation heatmap ---
st.subheader("üß© –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")

fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(df.corr(), annot=False, cmap="Blues")
st.pyplot(fig)

# --- Train model button ---
st.header("ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
if st.button("–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):

    if "churn" not in df.columns:
        st.error("–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ 'churn'")
        st.stop()

    X = df.drop("churn", axis=1)
    y = df["churn"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42
    )

    model = RandomForestClassifier(n_estimators=300, random_state=42)
    model.fit(X_train, y_train)

    preds = model.predict(X_test)
    probs = model.predict_proba(X_test)[:, 1]

    st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")

    st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")
    st.write("Accuracy:", accuracy_score(y_test, preds))
    st.write("ROC-AUC:", roc_auc_score(y_test, probs))

    st.text("Classification report:")
    st.text(classification_report(y_test, preds))

    # --- Graph #3: Confusion Matrix ---
    st.subheader("üü• Confusion Matrix")

    cm = confusion_matrix(y_test, preds)
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Reds")
    st.pyplot(fig)

    # --- Graph #4: Feature importance ---
    st.subheader("üå≤ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Importance)")

    importances = pd.Series(model.feature_importances_, index=X.columns)

    fig, ax = plt.subplots(figsize=(8, 6))
    importances.sort_values().plot(kind="barh", ax=ax)
    st.pyplot(fig)
